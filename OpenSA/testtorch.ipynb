{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:17<00:00, 582909.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 110311.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1592245/1648877 [05:33<00:11, 4778.59it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m DOWNLOAD_MNIST \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 下载mnist手写数据集\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 训练集\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(  \n\u001b[0;32m     17\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./MNIST/\u001b[39m\u001b[38;5;124m'\u001b[39m,                      \n\u001b[0;32m     18\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,                            \n\u001b[0;32m     19\u001b[0m     transform \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),                                                \n\u001b[0;32m     20\u001b[0m     download\u001b[38;5;241m=\u001b[39mDOWNLOAD_MNIST \n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 测试集\u001b[39;00m\n\u001b[0;32m     24\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./MNIST/\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# train设置为False表示获取测试集\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:187\u001b[0m, in \u001b[0;36mMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 187\u001b[0m     download_and_extract_archive(url, download_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, filename\u001b[38;5;241m=\u001b[39mfilename, md5\u001b[38;5;241m=\u001b[39mmd5)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download (trying next):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torchvision\\datasets\\utils.py:378\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    376\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 378\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[0;32m    380\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torchvision\\datasets\\utils.py:151\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# check integrity of downloaded file\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found or corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torch.utils.data as Data\n",
    " \n",
    "torch.manual_seed(1)  # 设置随机种子, 用于复现\n",
    " \n",
    "# 超参数\n",
    "EPOCH = 1       # 前向后向传播迭代次数\n",
    "LR = 0.001      # 学习率 learning rate \n",
    "BATCH_SIZE = 50 # 批量训练时候一次送入数据的size\n",
    "DOWNLOAD_MNIST = True \n",
    " \n",
    "# 下载mnist手写数据集\n",
    "# 训练集\n",
    "train_data = torchvision.datasets.MNIST(  \n",
    "    root = './MNIST/',                      \n",
    "    train = True,                            \n",
    "    transform = torchvision.transforms.ToTensor(),                                                \n",
    "    download=DOWNLOAD_MNIST \n",
    ")\n",
    " \n",
    "# 测试集\n",
    "test_data = torchvision.datasets.MNIST(root='./MNIST/', train=False)  # train设置为False表示获取测试集\n",
    " \n",
    "# 一个批训练 50个样本, 1 channel通道, 图片尺寸 28x28 size:(50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ") \n",
    "#  测试数据预处理；只测试前2000个\n",
    "test_x = torch.unsqueeze(test_data.data,dim=1).float()[:2000] / 255.0\n",
    "# shape from (2000, 28, 28) to (2000, 1, 28, 28)\n",
    "test_y = test_data.targets[:2000]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    " \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(                      # 输入的图片 （1，28，28）\n",
    "                in_channels=1,\n",
    "                out_channels=16,            # 经过一个卷积层之后 （16,28,28）\n",
    "                kernel_size=5,\n",
    "                stride=1,                    # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)      # 经过池化层处理，维度为（16,14,14）\n",
    "        )\n",
    " \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(                         # 输入（16,14,14）\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),                                 # 输出（32,14,14）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)        # 输出（32,7,7）\n",
    "        )\n",
    " \n",
    "        self.out = nn.Linear(32*7*7,10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)                     #（batch_size,16,14,14）\n",
    "        x = self.conv2(x)                     # 输出（batch_size,32,7,7）\n",
    "        x = x.view(x.size(0),-1)              # (batch_size,32*7*7)\n",
    "        out = self.out(x)                     # (batch_size,10)\n",
    "        return out\n",
    " \n",
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=LR) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
